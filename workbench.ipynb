{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "#import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from util import *\n",
    "from darknet import Darknet\n",
    "from preprocess import prep_image, inp_to_image, letterbox_image\n",
    "import pandas as pd\n",
    "import random \n",
    "import pickle as pkl\n",
    "import progressbar\n",
    "import os\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_input(input_dim, CUDA):\n",
    "    img = cv2.imread(\"dog-cycle-car.png\")\n",
    "    img = cv2.resize(img, (input_dim, input_dim)) \n",
    "    img_ =  img[:,:,::-1].transpose((2,0,1))\n",
    "    img_ = img_[np.newaxis,:,:,:]/255.0\n",
    "    img_ = torch.from_numpy(img_).float()\n",
    "    img_ = Variable(img_)\n",
    "    \n",
    "    if CUDA:\n",
    "        img_ = img_.cuda()\n",
    "    \n",
    "    return img_\n",
    "\n",
    "def prep_image(img, inp_dim):\n",
    "    \"\"\"\n",
    "    Prepare image for inputting to the neural network. \n",
    "    \n",
    "    Returns a Variable \n",
    "    \"\"\"\n",
    "\n",
    "    orig_im = img\n",
    "    dim = orig_im.shape[1], orig_im.shape[0]\n",
    "    img = (letterbox_image(orig_im, (inp_dim, inp_dim)))\n",
    "    img_ = img[:,:,::-1].transpose((2,0,1)).copy()\n",
    "    img_ = torch.from_numpy(img_).float().div(255.0).unsqueeze(0)\n",
    "    return img_, orig_im, dim\n",
    "\n",
    "def write(x, img):\n",
    "    c1 = tuple(x[1:3].float())\n",
    "    c2 = tuple(x[3:5].float())\n",
    "    cls = int(x[-1])\n",
    "    confidence=round(float(x[6]),2)\n",
    "    label = \"{0}:{1}\".format(classes[cls],confidence)\n",
    "    color = random.choice(colors)\n",
    "    cv2.rectangle(img, c1, c2,color, 1)\n",
    "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
    "    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
    "    cv2.rectangle(img, c1, c2,color, -1)\n",
    "    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1);\n",
    "    return img\n",
    "\n",
    "def init_folder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    for f in os.listdir(folder):\n",
    "        os.remove(folder + os.path.sep + f)\n",
    "        \n",
    "def get_classes(x):\n",
    "    return int(x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video = \"test2.avi\"\n",
    "confidence = 0.6\n",
    "nms_thresh = 0.5\n",
    "cfg= os.path.join(\"cfg\",\"model.cfg\")\n",
    "weights = \"model.weights\"\n",
    "classes_file=os.path.join(\"data\",\"model.names\")\n",
    "input_files='input'\n",
    "reso = \"256\"\n",
    "num_classes = 3\n",
    "start=0\n",
    "output_predictions='pred'\n",
    "output_frames='frames'\n",
    "sep=0\n",
    "clipFolder='clip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network.....\n",
      "Network successfully loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds12/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "bbox_attrs = 5 + num_classes\n",
    "print(\"Loading network.....\")\n",
    "model = Darknet(cfg)\n",
    "model.load_weights(weights)\n",
    "print(\"Network successfully loaded\")\n",
    "model.net_info[\"height\"] = reso\n",
    "inp_dim = int(model.net_info[\"height\"])\n",
    "assert inp_dim % 32 == 0 \n",
    "assert inp_dim > 32\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "        \n",
    "model(get_test_input(inp_dim, CUDA), CUDA)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds12/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "  0% (6 of 22525) |                      | Elapsed Time: 0:00:00 ETA:   0:07:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-122443-123944-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (5 of 22531) |                      | Elapsed Time: 0:00:00 ETA:   0:08:15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-133943-135444-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (5 of 22533) |                      | Elapsed Time: 0:00:00 ETA:   0:08:34"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-170943-172443-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (5 of 22537) |                      | Elapsed Time: 0:00:00 ETA:   0:08:10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-140943-142443-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6 of 22528) |                      | Elapsed Time: 0:00:00 ETA:   0:06:37"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-165443-170944-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (7 of 22528) |                      | Elapsed Time: 0:00:00 ETA:   0:05:58"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-143943-145443-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6 of 22519) |                      | Elapsed Time: 0:00:00 ETA:   0:06:38"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-135443-140944-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6 of 22533) |                      | Elapsed Time: 0:00:00 ETA:   0:06:34"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-155443-160944-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (7 of 22528) |                      | Elapsed Time: 0:00:00 ETA:   0:06:10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-163943-165444-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6 of 22537) |                      | Elapsed Time: 0:00:00 ETA:   0:07:19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-150943-152443-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (5 of 22539) |                      | Elapsed Time: 0:00:00 ETA:   0:07:54"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-130943-132444-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (7 of 22549) |                      | Elapsed Time: 0:00:00 ETA:   0:05:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-160943-162444-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (5 of 22525) |                      | Elapsed Time: 0:00:00 ETA:   0:07:44"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-125443-130943-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6 of 22487) |                      | Elapsed Time: 0:00:00 ETA:   0:06:36"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-162443-163944-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (5 of 22528) |                      | Elapsed Time: 0:00:00 ETA:   0:07:33"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-132443-133944-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6 of 22527) |                      | Elapsed Time: 0:00:00 ETA:   0:06:20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-123943-125444-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6 of 22539) |                      | Elapsed Time: 0:00:00 ETA:   0:06:20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-142443-143943-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (3 of 22525) |                      | Elapsed Time: 0:00:00 ETA:   0:13:33"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-113943-115443-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (5 of 22538) |                      | Elapsed Time: 0:00:00 ETA:   0:07:35"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-152443-153944-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (5 of 22541) |                      | Elapsed Time: 0:00:00 ETA:   0:07:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-110943-112444-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (5 of 22525) |                      | Elapsed Time: 0:00:00 ETA:   0:07:55"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-115443-120944-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6 of 22547) |                      | Elapsed Time: 0:00:00 ETA:   0:06:41"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-145443-150944-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6 of 22532) |                      | Elapsed Time: 0:00:00 ETA:   0:06:34"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-153943-155444-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6 of 22525) |                      | Elapsed Time: 0:00:00 ETA:   0:07:14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-120943-122443-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (5 of 22540) |                      | Elapsed Time: 0:00:00 ETA:   0:08:52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze input/0000000000000000-180521-112443-113944-01p406000000.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (22534 of 22540) |################# | Elapsed Time: 0:06:50 ETA:   0:00:00"
     ]
    }
   ],
   "source": [
    "init_folder(output_predictions)\n",
    "init_folder(output_frames)\n",
    "result=pd.DataFrame(columns=['file','countPerson','countBags','time','frame','timeInterval'])\n",
    "ti=0\n",
    "timeCursor=0\n",
    "for video in os.listdir(input_files):\n",
    "    video=os.path.join(input_files, video)\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    assert cap.isOpened(), 'Cannot capture source'    \n",
    "    frames = 0\n",
    "    count_frames=int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('Analyze '+video)\n",
    "    bar=progressbar.ProgressBar(max_value=count_frames)\n",
    "    count_files=len(os.listdir(path=output_frames))\n",
    "    last_success_frame=0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            img, orig_im, dim = prep_image(frame, inp_dim)\n",
    "            im_dim = torch.FloatTensor(dim).repeat(1,2)                        \n",
    "            if CUDA:\n",
    "                im_dim = im_dim.cuda()\n",
    "                img = img.cuda()          \n",
    "            with torch.no_grad():   \n",
    "                output = model(Variable(img), CUDA)\n",
    "            #print(output)\n",
    "            bar.update(frames)\n",
    "            frames += 1\n",
    "            output = write_results(output, confidence, num_classes, nms = True, nms_conf = nms_thresh)\n",
    "            if type(output) == int:\n",
    "                #frames += 1\n",
    "                #print(\"FPS of the video is {:5.2f}\".format( frames / (time.time() - start)))\n",
    "                #cv2.imshow(\"frame\", orig_im)\n",
    "                key = cv2.waitKey(1)\n",
    "                if key & 0xFF == ord('q'):\n",
    "                    break\n",
    "                continue\n",
    "            if cap.get(cv2.CAP_PROP_POS_MSEC)>(timeCursor+60000):\n",
    "                ti+=1\n",
    "            timeCursor=cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            \n",
    "            im_dim = im_dim.repeat(output.size(0), 1)\n",
    "            scaling_factor = torch.min(inp_dim/im_dim,1)[0].view(-1,1)\n",
    "            output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim[:,0].view(-1,1))/2\n",
    "            output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim[:,1].view(-1,1))/2\n",
    "            output[:,1:5] /= scaling_factor\n",
    "            for i in range(output.shape[0]):\n",
    "                output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim[i,0])\n",
    "                output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim[i,1])\n",
    "            classes = load_classes(classes_file)\n",
    "            colors = pkl.load(open(\"pallete\", \"rb\"))\n",
    "            \n",
    "            counter=frames+count_files\n",
    "            image_file='frame'+str(counter)+'.jpg'\n",
    "            cv2.imwrite(output_frames+os.path.sep+image_file, orig_im)\n",
    "            list(map(lambda x: write(x, orig_im), output)) \n",
    "            cv2.imwrite(output_predictions+os.path.sep+image_file, orig_im)\n",
    "            preds=list(map(lambda x: get_classes(x), output)) \n",
    "\n",
    "            persons=preds.count(2)\n",
    "            result.loc[counter]=[video,persons,len(preds)-persons,timeCursor,cap.get(cv2.CAP_PROP_POS_FRAMES),ti]\n",
    "            \n",
    "            #cv2.imshow(\"frame\", orig_im)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key & 0xFF == ord('q'):\n",
    "                break\n",
    "            last_success_frame=frames\n",
    "            \n",
    "            \n",
    "            #print(\"FPS of the video is {:5.2f}\".format( frames / (time.time() - start)))\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "for each in result.sample(n=5)[['countPerson','countBags']].iterrows():\n",
    "    images.append(Image(filename=output_frames+os.path.sep+'frame'+str(int(each[0]))+'.jpg',retina=True))\n",
    "    images.append(Image(filename=output_predictions+os.path.sep+'frame'+str(int(each[0]))+'.jpg',retina=True))\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "for each in result.sample(n=5)[['countPerson','countBags']].iterrows():\n",
    "    images.append('frame'+str(int(each[0]))+'.jpg')\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in images:\n",
    "    image_f = cv2.imread(output_frames+os.path.sep+each)\n",
    "    image_p = cv2.imread(output_predictions+os.path.sep+each)\n",
    "# I just resized the image to a quarter of its original size\n",
    "    image_f = cv2.resize(image_f, (0, 0), None, .25, .25)\n",
    "    image_p = cv2.resize(image_p, (0, 0), None, .25, .25)\n",
    "    numpy_horizontal = np.hstack((image_f, image_p))\n",
    "    numpy_horizontal_concat = np.concatenate((image_f, image_p), axis=1)\n",
    "\n",
    "    cv2.imshow('Numpy Horizontal', numpy_horizontal_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Main', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"kuju.jpg\") #Load image\n",
    "cv2.imshow('Main', image)\n",
    "aa = cv2.imread(\"kuju.jpg\",0) #Apply filter bb = cv2.imread(\"kuju.jpg\",1)\n",
    "\n",
    "cv2.imshow(\"frame1\",aa) #display in windows cv2.imshow(\"frame2\",bb)\n",
    "\n",
    "cv2.waitKey(0) cv2.destroyAllWindows()**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in result.sample(n=5)[['countPerson','countBags']].iterrows():\n",
    "    display(Image(filename=output_frames+os.path.sep+'frame'+str(int(each[0]))+'.jpg',retina=True))\n",
    "    display(Image(filename=output_predictions+os.path.sep+'frame'+str(int(each[0]))+'.jpg',retina=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in result.timeInterval.unique():\n",
    "    start=result[result['timeInterval']==each].time.min()\n",
    "    finish=result[result['timeInterval']==each].time.max()\n",
    "    clip = ffmpeg_extract_subclip(result[result['timeInterval']==each].file.iloc[0],start/1000,finish/1000,os.path.join(clipFolder,'clip'+str(each)+'.mp4'));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
